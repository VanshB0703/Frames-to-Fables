{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-Processing"
      ],
      "metadata": {
        "id": "Y021k8bPcKcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "aMgBDxR_YP0m"
      },
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col_names = ['card', 'reports', 'age', 'income', 'share', 'expenditure',\n",
        "             'owner', 'selfempl', 'dependents', 'months', 'majorcards', 'active']\n",
        "\n",
        "data = pd.read_csv(\"AER_credit_card_data.csv\", skiprows=1, header=None, names=col_names)\n"
      ],
      "metadata": {
        "id": "OST84pftYQ6n"
      },
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['card'] = data['card'].map({'yes': 1, 'no': 0})\n",
        "data['owner'] = data['owner'].map({'yes': 1, 'no': 0})\n",
        "data['selfempl'] = data['selfempl'].map({'yes': 1, 'no': 0})"
      ],
      "metadata": {
        "id": "VoeOEdEhYUmo"
      },
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_scale = ['reports', 'age', 'income', 'share', 'expenditure','dependents','months', 'majorcards', 'active']\n",
        "scaler = StandardScaler()\n",
        "data[cols_to_scale] = scaler.fit_transform(data[cols_to_scale])"
      ],
      "metadata": {
        "id": "BG1mRybAYWTo"
      },
      "execution_count": 263,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision tree"
      ],
      "metadata": {
        "id": "KaqFUGTacTqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node():\n",
        "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, info_gain=None, value=None):\n",
        "        self.feature_index = feature_index\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.info_gain = info_gain\n",
        "        self.value = value"
      ],
      "metadata": {
        "id": "4aBvBlslYXoz"
      },
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTreeClassifier():\n",
        "    def __init__(self, min_samples_split=2, max_depth=2):\n",
        "        self.root = None\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth = max_depth\n",
        "\n",
        "    def build_tree(self, dataset, curr_depth=0):\n",
        "        X = dataset[:, :-1]\n",
        "        Y = dataset[:, -1]\n",
        "        num_samples, num_features = X.shape\n",
        "\n",
        "        if num_samples >= self.min_samples_split and curr_depth <= self.max_depth:\n",
        "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
        "            if best_split[\"info_gain\"] > 0:\n",
        "                left_subtree = self.build_tree(best_split[\"dataset_left\"], curr_depth + 1)\n",
        "                right_subtree = self.build_tree(best_split[\"dataset_right\"], curr_depth + 1)\n",
        "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"],\n",
        "                            left_subtree, right_subtree, best_split[\"info_gain\"])\n",
        "\n",
        "        leaf_value = self.calculate_leaf_value(Y)\n",
        "        return Node(value=leaf_value)\n",
        "\n",
        "    def get_best_split(self, dataset, num_samples, num_features):\n",
        "        best_split = {}\n",
        "        max_info_gain = -float(\"inf\")\n",
        "\n",
        "        for feature_index in range(num_features):\n",
        "            feature_values = dataset[:, feature_index]\n",
        "            possible_thresholds = np.unique(feature_values)\n",
        "\n",
        "            for threshold in possible_thresholds:\n",
        "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
        "                if len(dataset_left) > 0 and len(dataset_right) > 0:\n",
        "                    y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
        "                    curr_info_gain = self.information_gain(y, left_y, right_y, \"gini\")\n",
        "                    if curr_info_gain > max_info_gain:\n",
        "                        best_split = {\n",
        "                            \"feature_index\": feature_index,\n",
        "                            \"threshold\": threshold,\n",
        "                            \"dataset_left\": dataset_left,\n",
        "                            \"dataset_right\": dataset_right,\n",
        "                            \"info_gain\": curr_info_gain\n",
        "                        }\n",
        "                        max_info_gain = curr_info_gain\n",
        "\n",
        "        return best_split\n",
        "\n",
        "    def split(self, dataset, feature_index, threshold):\n",
        "        left = np.array([row for row in dataset if row[feature_index] <= threshold])\n",
        "        right = np.array([row for row in dataset if row[feature_index] > threshold])\n",
        "        return left, right\n",
        "\n",
        "    def information_gain(self, parent, l_child, r_child, mode=\"entropy\"):\n",
        "        weight_l = len(l_child) / len(parent)\n",
        "        weight_r = len(r_child) / len(parent)\n",
        "        if mode == \"gini\":\n",
        "            gain = self.gini_index(parent) - (weight_l * self.gini_index(l_child) + weight_r * self.gini_index(r_child))\n",
        "        else:\n",
        "            gain = self.entropy(parent) - (weight_l * self.entropy(l_child) + weight_r * self.entropy(r_child))\n",
        "        return gain\n",
        "\n",
        "    def entropy(self, y):\n",
        "        class_labels, counts = np.unique(y, return_counts=True)\n",
        "        probabilities = counts / counts.sum()\n",
        "        return -np.sum(probabilities * np.log2(probabilities))\n",
        "\n",
        "    def gini_index(self, y):\n",
        "        class_labels, counts = np.unique(y, return_counts=True)\n",
        "        probabilities = counts / counts.sum()\n",
        "        return 1 - np.sum(probabilities**2)\n",
        "\n",
        "    def calculate_leaf_value(self, Y):\n",
        "        values, counts = np.unique(Y, return_counts=True)\n",
        "        return values[np.argmax(counts)]\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        dataset = np.concatenate((X, Y), axis=1)\n",
        "        self.root = self.build_tree(dataset)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return [self.make_prediction(x, self.root) for x in X]\n",
        "\n",
        "    def make_prediction(self, x, tree):\n",
        "        if tree.value is not None:\n",
        "            return tree.value\n",
        "        feature_val = x[tree.feature_index]\n",
        "        if feature_val <= tree.threshold:\n",
        "            return self.make_prediction(x, tree.left)\n",
        "        else:\n",
        "            return self.make_prediction(x, tree.right)\n",
        "\n",
        "    def print_tree(self, tree=None, indent=\" \"):\n",
        "        if tree is None:\n",
        "            tree = self.root\n",
        "        if tree.value is not None:\n",
        "            print(tree.value)\n",
        "        else:\n",
        "            print(\"X_\" + str(tree.feature_index), \"<=\", tree.threshold, \"?\", tree.info_gain)\n",
        "            print(indent + \"Left:\", end=\" \")\n",
        "            self.print_tree(tree.left, indent + \"  \")\n",
        "            print(indent + \"Right:\", end=\" \")\n",
        "            self.print_tree(tree.right, indent + \"  \")"
      ],
      "metadata": {
        "id": "myXEmHEcYY4v"
      },
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop('card', axis=1).values\n",
        "Y = data['card'].values.reshape(-1, 1)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=41)\n"
      ],
      "metadata": {
        "id": "ychrCWxRYdwO"
      },
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = DecisionTreeClassifier(min_samples_split=3, max_depth=3)\n",
        "clf.fit(X_train, Y_train)\n",
        "clf.print_tree()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7K6YkQA7YfQD",
        "outputId": "d39be8e0-8706-49ae-bbea-578d5fa6dd0c"
      },
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_4 <= -0.680067582792967 ? 0.33149008940208585\n",
            " Left: X_0 <= -0.3393968014785687 ? 0.0034772152880162416\n",
            "   Left: X_10 <= 0.3177691062974968 ? 0.012424375031437257\n",
            "     Left: X_1 <= -0.8100556113436747 ? 0.0059838366420871675\n",
            "       Left: 0.0\n",
            "       Right: 0.0\n",
            "     Right: X_5 <= 0.0 ? 0.1519097222222222\n",
            "       Left: 1.0\n",
            "       Right: 0.0\n",
            "   Right: X_6 <= 0.0 ? 0.0019750071818443616\n",
            "     Left: 0.0\n",
            "     Right: X_1 <= 1.4830840679064266 ? 0.21875\n",
            "       Left: 0.0\n",
            "       Right: 1.0\n",
            " Right: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = np.array(clf.predict(X_test)).reshape(-1, 1)\n",
        "print(\"Accuracy:\", accuracy_score(Y_test, Y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--RM7JdJXiN3",
        "outputId": "17795f62-2fe4-42f0-cf64-3f9f0627c693"
      },
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9659090909090909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "Y_pred = np.array(Y_pred).astype(int)\n",
        "Y_true = Y_test.flatten()\n",
        "\n",
        "cm = confusion_matrix(Y_true, Y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "cr = classification_report(Y_true, Y_pred, target_names=[\"Rejected (0)\", \"Accepted (1)\"])\n",
        "print(\"\\nClassification Report:\")\n",
        "print(cr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aAAIiBzX11S",
        "outputId": "9c5fb049-6d80-4d77-8d0e-efcf2388033e"
      },
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[ 49   2]\n",
            " [  7 206]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Rejected (0)       0.88      0.96      0.92        51\n",
            "Accepted (1)       0.99      0.97      0.98       213\n",
            "\n",
            "    accuracy                           0.97       264\n",
            "   macro avg       0.93      0.96      0.95       264\n",
            "weighted avg       0.97      0.97      0.97       264\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "RHTK-N0BcbDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "X = data.drop('card', axis=1).values\n",
        "Y = data['card'].values\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
        "\n",
        "rf_model.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = rf_model.predict(X_test)\n",
        "\n",
        "print( accuracy_score(Y_test, Y_pred))\n",
        "print(confusion_matrix(Y_test, Y_pred))\n",
        "print( classification_report(Y_test, Y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BbORV8gcEYj",
        "outputId": "0da7e7d2-27d6-435b-80a3-e3b6565290ca"
      },
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9772727272727273\n",
            "[[ 62   0]\n",
            " [  6 196]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      1.00      0.95        62\n",
            "           1       1.00      0.97      0.98       202\n",
            "\n",
            "    accuracy                           0.98       264\n",
            "   macro avg       0.96      0.99      0.97       264\n",
            "weighted avg       0.98      0.98      0.98       264\n",
            "\n"
          ]
        }
      ]
    }
  ]
}